# -*- coding: utf-8 -*-
import time
import numpy as np
import cv2
import matplotlib.pyplot as plt
from libraries import *
import argparse

pause_frame = False 
# pause_frame = True #wait for keypress before playing next frame

parser = argparse.ArgumentParser(description='Frametime Analyser')
parser.add_argument('file_path', type=str, help='Path to the video file')
args = parser.parse_args()

if not args.file_path:
    print("No file path provided. Please provide a video file path.")
    exit(1)

file_path = args.file_path
cap = cv2.VideoCapture(file_path)
if not cap.isOpened():
    print(f"Error: Could not open video file {file_path}")
    exit(1)

fvs = FileVideoStream(file_path).start()
time.sleep(3)
# start the FPS timer
# fps = FPS().start()



count = 0
frametime = 0
frametime_text = "None"


frametime_samples = 40
frametime_graph = [0]*frametime_samples #list of previous frametimes


fps_list = [0]*60 # 0 means repeated frame, 1 means unique frame. summation of fps_list gives the current fps
fps = 0
fps_graph_samples = 580
fps_graph = [0]*fps_graph_samples


perf_list = [0] #list of miliseconds taken for each segment of code
timestamp_before_imshow = None #timestamp to be taken before cv2.imshow
moving_avg_brightness = 0	#exponentially decaying moving avg of previous frames' brightness


while fvs.more():  
    if count == 0:
        frame = fvs.read()
        prev_frame = frame
        height = len(frame)
        width = len(frame[0])
        timestamp_before_imshow = cv2.getTickCount()
    perf_list.append((cv2.getTickCount() - timestamp_before_imshow )/ cv2.getTickFrequency()*1000-sum(perf_list))

    # text_color = (0,0,0)
    text_color = (255,255,255)
    # graph_color = (128,0,0)
    graph_color = (93, 232, 130)
    shadow_color = (0,0,0)

    src_frame = fvs.read()
    # frame = src_frame
    frame = src_frame.copy()
    perf_list.append((cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000-sum(perf_list))

    # cv2.imshow('frame',prev_frame)

    # #downscale before calculating difference
    scale = 0.1
    cropped_frame = cv2.resize(frame, (0,0), fx=scale, fy=scale)
    cropped_prev_frame = cv2.resize(prev_frame, (0,0), fx=scale, fy=scale) 
    

    #convert to grayscale
    cropped_frame = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2GRAY)
    cropped_prev_frame = cv2.cvtColor(cropped_prev_frame, cv2.COLOR_BGR2GRAY)


    #calculate frame difference
    frame_diff = cv2.absdiff(cropped_frame, cropped_prev_frame)
    average = frame_diff.mean(axis=0).mean(axis=0)
    if count == 1:
        moving_avg_brightness = average
    perf_list.append((cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000-sum(perf_list))



    threshold = 0.25*moving_avg_brightness #threshold below which a frame is considered "identical" or dropped
    if average < threshold:
        fps_list.pop(0)
        fps_list.append(0)
        fps = sum(fps_list)
        
        fps_graph.pop(0)
        fps_graph.append(fps)
    else:
        result = ""
        frametime_text = frametime
        frametime_graph.pop(0)
        frametime_graph.append(frametime)
        
        fps_list.pop(0)
        fps_list.append(1)
        fps = sum(fps_list)
        
        fps_graph.pop(0)
        fps_graph.append(fps)
        frametime = 0	#frametime will be incremented at end of loop


    if(count)<60:
        fps = ""
    # print (average, moving_avg_brightness, result)
    moving_avg_brightness = (moving_avg_brightness + average/3)*3/4



    # text_to_write = '{:4.2f}'.format(average)+" "+str(frametime_text)+" "+result
    # texted_image =cv2.putText(frame, text=text_to_write, org=(200,200),fontFace=3, fontScale=3, color=(0,0,255), thickness=5)
    

    perf_list.append((cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000-sum(perf_list))


    text_to_write = str(fps)
    
    # texted_image =cv2.putText(frame, text=text_to_write, org=(1140,150),fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=2.2, color=(0,0,0), thickness=5)
    texted_image =cv2.putText(frame, text=text_to_write, org=(1140,150),fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=2, color=text_color, thickness=5)
    # texted_image =cv2.putText(frame, text="hello", org=(750,150),fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=2, color=(255,255,255), thickness=5)

    # resize = ResizeWithAspectRatio(texted_image, width=1280) #slow function, about 2.5ms
    resize = texted_image
    perf_list.append((cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000-sum(perf_list))


    #drawing frametime graph
    pt_width = 3
    pt_spacing = 3 #distance between center of 2 points
    pt_gap = pt_spacing - pt_width
    
    plt_origin_x = 60
    plt_origin_y = 480
    y_scale = 20

    # print frametime_graph
    for key, value in enumerate(frametime_graph):

        prev_ft = frametime_graph[key-1]
        if key ==0:
            continue
        if prev_ft == 0:
            continue        
        cv2.line(resize,(
                plt_origin_x + key*pt_spacing, 
                plt_origin_y-value*y_scale
            ),(
                plt_origin_x + key*pt_spacing + pt_width, 
                plt_origin_y-value*y_scale
            ),graph_color,2)
        if key !=0:
            cv2.line(resize,(
                    plt_origin_x + key*pt_spacing - pt_gap, 
                    plt_origin_y- prev_ft*y_scale
                ),(
                    plt_origin_x + key*pt_spacing, 
                    plt_origin_y-value*y_scale
                ),graph_color,2) #vertical
    cv2.rectangle(resize,(plt_origin_x,plt_origin_y-60),(plt_origin_x+frametime_samples*pt_spacing,plt_origin_y-10),text_color,2)
    cv2.putText(resize, text="16.7", org=(plt_origin_x+frametime_samples*pt_spacing+10,plt_origin_y-15),fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.4, color=text_color, thickness=1)
    cv2.putText(resize, text="33.3", org=(plt_origin_x+frametime_samples*pt_spacing+10,plt_origin_y- 15 - y_scale),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.4, color=text_color, thickness=1)
    # cv2.putText(resize, text="FRAMETIME (MS)", org=(plt_origin_x,plt_origin_y -70+1),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.5, color=(0,0,0), thickness=1)
    # cv2.putText(resize, text="FRAMETIME (MS)", org=(plt_origin_x+1,plt_origin_y -70),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.5, color=(0,0,0), thickness=1)
    cv2.putText(resize, text="FRAMETIME (MS)", org=(plt_origin_x,plt_origin_y -70),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.45, color=text_color, thickness=1)

    plt_origin_x = 60
    plt_origin_y = 500
    pt_width = 0
    pt_spacing = 2
    pt_gap = pt_spacing - pt_width
    y_scale = 4

    graph_speed = 2 #rate at which graph is moving from right to left

    for key, value in enumerate(fps_graph):
        if count<fps_graph_samples-key+60:
            continue
        if key == 0:
            continue
        prev_ft = fps_graph[key-1]
        start_point = plt_origin_x + key*graph_speed		, plt_origin_y-(prev_ft-60)*y_scale
        end_point 	= plt_origin_x + (key+1)*graph_speed	, plt_origin_y-(value-60)*y_scale
        cv2.line(resize,(start_point),(end_point),graph_color,2)
    # cv2.rectangle(resize,(plt_origin_x+1,plt_origin_y+1),(plt_origin_x+fps_graph_samples*pt_spacing+1,plt_origin_y+40*y_scale+1),shadow_color,1)
    cv2.rectangle(resize,(plt_origin_x,plt_origin_y),(plt_origin_x+fps_graph_samples*pt_spacing,plt_origin_y+40*y_scale),text_color,2)
    cv2.line(resize,(plt_origin_x,plt_origin_y+20*y_scale),(plt_origin_x+fps_graph_samples*pt_spacing,plt_origin_y+20*y_scale),text_color,1)
    cv2.putText(resize, text="FRAME-RATE (FPS)", org=(plt_origin_x+fps_graph_samples*pt_spacing -150,plt_origin_y-15),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.5, color=text_color, thickness=1)
    cv2.putText(resize, text="60", org=(plt_origin_x+fps_graph_samples*pt_spacing+10,plt_origin_y+5),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.4, color=text_color, thickness=1)
    cv2.putText(resize, text="40", org=(plt_origin_x+fps_graph_samples*pt_spacing+10,plt_origin_y+21*y_scale),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.4, color=text_color, thickness=1)
    cv2.putText(resize, text="20", org=(plt_origin_x+fps_graph_samples*pt_spacing+10,plt_origin_y+41*y_scale),fontFace=cv2.	FONT_HERSHEY_DUPLEX, fontScale=0.4, color=text_color, thickness=1)
        # if key !=0:
            # cv2.line(resize,(plt_origin_x + key*pt_spacing - pt_gap, plt_origin_y- prev_ft*10),(plt_origin_x + key*pt_spacing, plt_origin_y-value*10),graph_color,1)


    # Calculate total time elapse since previous cv2.imshow, for PERFORMANCE ANALYSIS
    calc_time = (cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000
    # print calc_time
    if calc_time>16:


        perf_list.append((cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000-sum(perf_list))
        perf_list.append(calc_time)
        perf_list = list(np.around(np.array(perf_list),2))

        print("XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX")        
        print(perf_list)

      
    #vsync
    while ((cv2.getTickCount() - timestamp_before_imshow)/cv2.getTickFrequency()*10**6< 10**6/60.01):
        continue
    # print (cv2.getTickCount() - timestamp_before_imshow)/cv2.getTickFrequency()*1000 #check if equal 16.666, disable to ensure vsync works
    timestamp_before_imshow = cv2.getTickCount()
    cv2.imshow('frame',resize)
    # cv2.imshow('frame',frame_diff)
    # cv2.imshow('frame',ResizeWithAspectRatio(frame_diff,width=1280))
    perf_list =[(cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000]


    prev_frame = src_frame
    count = count + 1
    frametime = frametime + 1


    # if pause_frame:
	   #  if cv2.waitKey(0) & 0xFF == ord('q'):
    #     	break
    # else:    
	   #  if cv2.waitKey(1) & 0xFF == ord('q'):
	   #      break
    if cv2.waitKey(1) & 0xFF == ord('q'):
          break

    perf_list.append((cv2.getTickCount() - timestamp_before_imshow)/ cv2.getTickFrequency()*1000-sum(perf_list))

cap.release()
cv2.destroyAllWindows()